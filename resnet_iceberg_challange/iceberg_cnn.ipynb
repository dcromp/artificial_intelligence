{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.misc import imresize\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "\n",
    "# Keras imports\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Add, Activation, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dropout, Input, LeakyReLU, BatchNormalization, concatenate\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.optimizers import RMSprop, Adagrad, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet')\n",
    "vgg19 = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dir = '/Users/dcromp/Documents/projects/ice_bergs/data/processed/train.json'\n",
    "test_dir = '/Users/dcromp/Documents/projects/ice_bergs/test/processed/test.json'\n",
    "batch_size = 32\n",
    "\n",
    "# Load data and calculate batch sizes\n",
    "with open(train_dir) as data_file:    \n",
    "    train_json = json.load(data_file)\n",
    "    whole_batch = int(len(train_json) / batch_size)\n",
    "    over_batch = int(len(train_json) % batch_size)\n",
    "    total_batches = whole_batch\n",
    "    if over_batch != 0:\n",
    "        total_batches = total_batches + 1    \n",
    "        \n",
    "with open(test_dir) as data_file:    \n",
    "    test_json = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_avg(train_json, test_json):\n",
    "    \n",
    "    # Calculate size of data set\n",
    "    num_samples = len(train_json) + len(test_json)\n",
    "    channel_dim = len(train_json[0]['band_1'])\n",
    "    channels = 2\n",
    "    \n",
    "    #Initlize sum and counts\n",
    "    band_1_sum = 0\n",
    "    band_2_sum = 0\n",
    "    angle_sum = 0\n",
    "    angle_count = 0\n",
    "    band_1_max = 0\n",
    "    band_1_min = 0\n",
    "    band_2_max = 0\n",
    "    band_2_min = 0\n",
    "    \n",
    "    # Loop over training data\n",
    "    for sample in train_json:\n",
    "        band_1_sum = band_1_sum + sum(sample['band_1'])\n",
    "        band_2_sum = band_2_sum + sum(sample['band_2'])\n",
    "        \n",
    "        if max(sample['band_1']) > band_1_max:\n",
    "            band_1_max = max(sample['band_1'])\n",
    "        if min(sample['band_1']) < band_1_min:\n",
    "            band_1_min = min(sample['band_1'])\n",
    "            \n",
    "        if max(sample['band_2']) > band_2_max:\n",
    "            band_2_max = max(sample['band_2'])\n",
    "        if min(sample['band_2']) < band_2_min:\n",
    "            band_2_min = min(sample['band_2'])\n",
    "        \n",
    "        if isinstance(sample['inc_angle'], str):\n",
    "            pass\n",
    "        else:\n",
    "            angle_sum = angle_sum + sample['inc_angle']\n",
    "            angle_count = angle_count + 1\n",
    "            \n",
    "    # Loop over test data\n",
    "    for sample in test_json:\n",
    "        band_1_sum = band_1_sum + sum(sample['band_1'])\n",
    "        band_2_sum = band_2_sum + sum(sample['band_2'])\n",
    "        \n",
    "        \n",
    "        if max(sample['band_1']) > band_1_max:\n",
    "            band_1_max = max(sample['band_1'])\n",
    "        if min(sample['band_1']) < band_1_min:\n",
    "            band_1_min = min(sample['band_1'])\n",
    "            \n",
    "        if max(sample['band_2']) > band_2_max:\n",
    "            band_2_max = max(sample['band_2'])\n",
    "        if min(sample['band_2']) < band_2_min:\n",
    "            band_2_min = min(sample['band_2'])\n",
    "        \n",
    "        if isinstance(sample['inc_angle'], str):\n",
    "            pass\n",
    "        else:\n",
    "            angle_sum = angle_sum + sample['inc_angle']\n",
    "            angle_count = angle_count + 1\n",
    "    \n",
    "    # Calculate averages\n",
    "    band_1_avg = band_1_sum / (num_samples * channel_dim)\n",
    "    band_2_avg = band_2_sum / (num_samples * channel_dim)\n",
    "    angle_avg = angle_sum / angle_count\n",
    "    \n",
    "    return band_1_avg, band_2_avg, angle_avg, band_1_max, band_1_min, band_2_max, band_2_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "band_1_avg, band_2_avg, angle_avg, band_1_max, band_1_min, band_2_max, band_2_min = data_avg(train_json, test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract labels\n",
    "labels = np.zeros(len(train_json))\n",
    "for index, sample in enumerate(train_json):\n",
    "    labels[index] = sample['is_iceberg']\n",
    "    \n",
    "# Extract IDs\n",
    "test_id = []\n",
    "for index, sample in enumerate(test_json):\n",
    "    test_id.append(sample['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract samples\n",
    "def sample_extractor(data_json):\n",
    "    \n",
    "    samples = np.zeros((len(data_json), 75, 75, 2))\n",
    "    angles = np.zeros(len(data_json))\n",
    "\n",
    "    for index, sample in enumerate(data_json):\n",
    "        band_1 = np.asarray(sample['band_1']).reshape(75,75)\n",
    "        band_2 = np.asarray(sample['band_2']).reshape(75,75)\n",
    "        samples[index][:,:,0] = band_1\n",
    "        samples[index][:,:,1] = band_2\n",
    "        inc_angle = sample['inc_angle']\n",
    "        if isinstance(sample['inc_angle'], str):\n",
    "            angles[index] = angle_avg\n",
    "        else: \n",
    "            angles[index] = sample['inc_angle']\n",
    "            \n",
    "    return samples, angles\n",
    "    \n",
    "train_samples, train_angles = sample_extractor(train_json)\n",
    "test_samples, test_angles = sample_extractor(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 75, 75, 2)\n",
      "(1604, 75, 75, 2)\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(1604, 75, 75, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'def scale_angles(train, test):\\n    print(train.shape)\\n    samples = np.concatenate((train, test), axis=0)\\n\\n    # Scale the samples between 0-1\\n    samples = samples + abs(np.amin(samples))   \\n    samples = samples / (np.amax(samples))\\n    \\n    print(np.amax(samples))\\n    print(np.amin(samples))\\n        \\n    return samples[:train.shape[0]], samples[train.shape[0]:]\\n\\ntrain_angles, test_angles = scale_angles(train_angles, test_angles)\\nprint(train_angles.shape)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minus the mean from the samples\n",
    "def mean_zero(samples, angles, band_1_avg, band_2_avg, angle_avg):\n",
    "    for index, sample in enumerate(samples):\n",
    "        samples[index][:,:,0] = np.subtract(sample[:,:,0], band_1_avg)\n",
    "        samples[index][:,:,1] = np.subtract(sample[:,:,1], band_2_avg)\n",
    "        angles[index] = np.subtract(angles[index], angle_avg)\n",
    "    return samples, angles\n",
    "\n",
    "train_samples, train_angles = mean_zero(train_samples, train_angles, band_1_avg, band_2_avg, angle_avg)\n",
    "test_samples, test_angles = mean_zero(test_samples, test_angles, band_1_avg, band_2_avg, angle_avg)\n",
    "print(train_samples.shape)\n",
    "\n",
    "\n",
    "def scale(train, test):\n",
    "    print(train.shape)\n",
    "    samples = np.concatenate((train, test), axis=0)\n",
    "\n",
    "    # Scale the samples between 0-1\n",
    "    samples[:,:,:,0] = samples[:,:,:,0] + abs(np.amin(samples[:,:,:,0]))\n",
    "    samples[:,:,:,1] = samples[:,:,:,1] + abs(np.amin(samples[:,:,:,1]))\n",
    "        \n",
    "    samples[:,:,:,0] = samples[:,:,:,0] / (np.amax(samples[:,:,:,0]))\n",
    "    samples[:,:,:,1] = samples[:,:,:,1] / (np.amax(samples[:,:,:,1]))\n",
    "    \n",
    "    print(np.amax(samples[:,:,:,0]))\n",
    "    print(np.amax(samples[:,:,:,1]))\n",
    "        \n",
    "    print(np.amin(samples[:,:,:,0]))\n",
    "    print(np.amin(samples[:,:,:,1]))\n",
    "        \n",
    "    return samples[:train.shape[0]], samples[train.shape[0]:]\n",
    "\n",
    "train_samples, test_samples = scale(train_samples, test_samples)\n",
    "print(train_samples.shape)\n",
    "\n",
    "\"\"\"def scale_angles(train, test):\n",
    "    print(train.shape)\n",
    "    samples = np.concatenate((train, test), axis=0)\n",
    "\n",
    "    # Scale the samples between 0-1\n",
    "    samples = samples + abs(np.amin(samples))   \n",
    "    samples = samples / (np.amax(samples))\n",
    "    \n",
    "    print(np.amax(samples))\n",
    "    print(np.amin(samples))\n",
    "        \n",
    "    return samples[:train.shape[0]], samples[train.shape[0]:]\n",
    "\n",
    "train_angles, test_angles = scale_angles(train_angles, test_angles)\n",
    "print(train_angles.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Layer definitions for more complex networks\n",
    "\n",
    "def conv_block(x, filters, size, stride=(2,2), mode='same', act=True):\n",
    "    x = Conv2D(filters, size, size, subsample=stride, border_mode=mode)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x) if act else x\n",
    "\n",
    "def res_block(ip, nf=15):\n",
    "    shortcut = ip\n",
    "    x = conv_block(ip, nf, 3, (1,1))\n",
    "    x = conv_block(x, nf, 3, (1,1), act=False)\n",
    "    # Check if we need to increase dimensionality of the shortcut\n",
    "    if shortcut.shape[3] != x.shape[3]:\n",
    "        shortcut = conv_block(shortcut, nf, 1, (1,1), act=False)\n",
    "    return Add()([x, shortcut])\n",
    "\n",
    "def deconv_block(x, filters, size, shape, stride=(2,2)):\n",
    "    x = Deconvolution2D(filters, size, size, subsample=stride, \n",
    "        border_mode='same', output_shape=(None,)+shape)(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def up_block(x, filters, size):\n",
    "    x = keras.layers.UpSampling2D()(x)\n",
    "    x = Convolution2D(filters, size, size, border_mode='same')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    return Activation('relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/kernel/__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(15, (3, 3), strides=(1, 1), padding=\"same\")`\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/kernel/__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (3, 3), strides=(1, 1), padding=\"same\")`\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/kernel/__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (1, 1), strides=(1, 1), padding=\"same\")`\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/kernel/__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(60, (3, 3), strides=(1, 1), padding=\"same\")`\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/kernel/__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(60, (1, 1), strides=(1, 1), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "band_input (InputLayer)         (None, 75, 75, 2)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 75, 75, 15)   285         band_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 75, 75, 15)   60          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 75, 75, 15)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 75, 75, 15)   2040        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 75, 75, 15)   60          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 75, 75, 15)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 75, 75, 15)   2040        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 75, 75, 15)   60          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 75, 75, 15)   0           batch_normalization_3[0][0]      \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 75, 75, 15)   2040        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 75, 75, 15)   60          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 75, 75, 15)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 75, 75, 15)   2040        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 75, 75, 15)   60          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 75, 75, 15)   0           batch_normalization_5[0][0]      \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 75, 75, 15)   2040        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 75, 75, 15)   60          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 75, 75, 15)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 75, 75, 15)   2040        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 75, 75, 15)   60          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 75, 75, 15)   0           batch_normalization_7[0][0]      \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 75, 75, 30)   4080        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 75, 75, 30)   120         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 75, 75, 30)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 75, 75, 30)   8130        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 75, 75, 30)   480         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 75, 75, 30)   120         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 75, 75, 30)   120         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 75, 75, 30)   0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 75, 75, 30)   8130        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 75, 75, 30)   120         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 75, 75, 30)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 75, 75, 30)   8130        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 75, 75, 30)   120         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 75, 75, 30)   0           batch_normalization_12[0][0]     \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 75, 75, 30)   8130        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 75, 75, 30)   120         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 75, 75, 30)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 75, 75, 30)   8130        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 75, 75, 30)   120         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 75, 75, 30)   0           batch_normalization_14[0][0]     \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 75, 75, 30)   8130        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 75, 75, 30)   120         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 75, 75, 30)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 75, 75, 30)   8130        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 75, 75, 30)   120         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 75, 75, 30)   0           batch_normalization_16[0][0]     \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 75, 75, 60)   16260       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 75, 75, 60)   240         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 75, 75, 60)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 75, 75, 60)   32460       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 75, 75, 60)   1860        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 75, 75, 60)   240         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 75, 75, 60)   240         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 75, 75, 60)   0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 75, 75, 60)   32460       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 75, 75, 60)   240         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 75, 75, 60)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 75, 75, 60)   32460       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 75, 75, 60)   240         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 75, 75, 60)   0           batch_normalization_21[0][0]     \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 75, 75, 60)   32460       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 75, 75, 60)   240         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 75, 75, 60)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 75, 75, 60)   32460       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 75, 75, 60)   240         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 75, 75, 60)   0           batch_normalization_23[0][0]     \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 75, 75, 60)   32460       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 75, 75, 60)   240         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 75, 75, 60)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 75, 75, 60)   32460       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 75, 75, 60)   240         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 75, 75, 60)   0           batch_normalization_25[0][0]     \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 75, 75, 60)   32460       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 75, 75, 60)   240         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 75, 75, 60)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 75, 75, 60)   32460       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 75, 75, 60)   240         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 75, 75, 60)   0           batch_normalization_27[0][0]     \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 75, 75, 60)   32460       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 75, 75, 60)   240         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 75, 75, 60)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 75, 75, 60)   32460       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 75, 75, 60)   240         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 75, 75, 60)   0           batch_normalization_29[0][0]     \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 37, 37, 60)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 82140)        0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1000)         82141000    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "angle_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1001)         0           dropout_2[0][0]                  \n",
      "                                                                 angle_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1001)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            1002        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 82,595,797\n",
      "Trainable params: 82,593,487\n",
      "Non-trainable params: 2,310\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Resnet model\n",
    "\n",
    "# Inputs\n",
    "band_input = Input(shape=(75, 75, 2), name='band_input')\n",
    "angle_input = Input(shape=(1,), name='angle_input')\n",
    "\n",
    "x=conv_block(band_input, 15, 3, (1,1))\n",
    "\n",
    "# 13 layer resnet\n",
    "for i in range(3): x=res_block(x)\n",
    "for i in range(4): x=res_block(x, 30)\n",
    "for i in range(6): x=res_block(x, 60)\n",
    "    \n",
    "x = AveragePooling2D(pool_size=2)(x)\n",
    "    \n",
    "cnn_out = Flatten()(x)\n",
    "\n",
    "x = Dropout(0.2)(cnn_out)\n",
    "x = Dense(1000, activation='relu')(cnn_out)\n",
    "x = Dropout(0.2)(x)\n",
    "x = concatenate([x, angle_input])\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[band_input, angle_input], outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(lr=0.1),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Create rotations of images\\nrotations = np.zeros((len(x_train), 75, 75, 2))\\nfor index, sample in enumerate(x_train):\\n    rotation = rotate(sample, angle = np.random.randint(1, 10), reshape = False)\\n    rotations[index] = rotation\\n    \\nflips = np.zeros((len(x_train), 75, 75, 2))\\nfor index, sample in enumerate(x_train):\\n    flip = np.fliplr(sample)\\n    flips[index] = flip\\n    \\nx_train = np.concatenate((x_train, rotations, flips), axis=0)\\nx_2_train = np.concatenate((x_2_train, x_2_train, x_2_train), axis=0)\\ny_train = np.concatenate((y_train, y_train, y_train), axis=0)\\n\\n\\nprint(rotations.shape, x_train.shape)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split out test data\n",
    "def unison_shuffled_copies(a, b, c):\n",
    "    assert len(a) == len(b)\n",
    "    assert len(b) == len(c)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p], c[p]\n",
    "\n",
    "train_samples, train_angles, labels = unison_shuffled_copies(train_samples, train_angles, labels)\n",
    "num_train = int(len(train_samples) * 0.2)\n",
    "\n",
    "x_train = train_samples[num_train:]\n",
    "x_2_train = train_angles[num_train:]\n",
    "y_train = labels[num_train:]\n",
    "x_test = train_samples[:num_train]\n",
    "x_2_test = train_angles[:num_train]\n",
    "y_test = labels[:num_train]\n",
    "\n",
    "\"\"\"\n",
    "# Create rotations of images\n",
    "rotations = np.zeros((len(x_train), 75, 75, 2))\n",
    "for index, sample in enumerate(x_train):\n",
    "    rotation = rotate(sample, angle = np.random.randint(1, 10), reshape = False)\n",
    "    rotations[index] = rotation\n",
    "    \n",
    "flips = np.zeros((len(x_train), 75, 75, 2))\n",
    "for index, sample in enumerate(x_train):\n",
    "    flip = np.fliplr(sample)\n",
    "    flips[index] = flip\n",
    "    \n",
    "x_train = np.concatenate((x_train, rotations, flips), axis=0)\n",
    "x_2_train = np.concatenate((x_2_train, x_2_train, x_2_train), axis=0)\n",
    "y_train = np.concatenate((y_train, y_train, y_train), axis=0)\n",
    "\n",
    "\n",
    "print(rotations.shape, x_train.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1027 samples, validate on 257 samples\n",
      "Epoch 1/2000\n",
      "1024/1027 [============================>.] - ETA: 1s - loss: 6.3850 - acc: 0.5869   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 00001: val_loss improved from inf to 7.40053, saving model to nov.weights.best.hdf5\n",
      "1027/1027 [==============================] - 629s 613ms/step - loss: 6.3976 - acc: 0.5862 - val_loss: 7.4005 - val_acc: 0.5409\n",
      "Epoch 2/2000\n",
      "1024/1027 [============================>.] - ETA: 1s - loss: 6.7064 - acc: 0.5801  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 00002: val_loss did not improve\n",
      "1027/1027 [==============================] - 582s 566ms/step - loss: 6.7180 - acc: 0.5794 - val_loss: 7.4005 - val_acc: 0.5409\n",
      "Epoch 3/2000\n",
      "1024/1027 [============================>.] - ETA: 1s - loss: 6.6910 - acc: 0.5811  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 00003: val_loss did not improve\n",
      "1027/1027 [==============================] - 558s 543ms/step - loss: 6.6870 - acc: 0.5813 - val_loss: 7.4605 - val_acc: 0.5370\n",
      "Epoch 4/2000\n",
      " 256/1027 [======>.......................] - ETA: 6:15 - loss: 6.9304 - acc: 0.5664\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='nov.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10)\n",
    "\n",
    "model.fit([x_train, x_2_train], y_train, batch_size=32, shuffle=True, validation_split=0.2, callbacks=[checkpointer, earlystop], initial_epoch=0, epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('nov.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Resnet 13 layers\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Non Scale angle\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale angle\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# large first feature map\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with flips, less rotation\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with rotations\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test original model\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "prediction_array = model.predict([test_samples, test_angles])\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_id\n",
    "submission['is_iceberg']=prediction_array.reshape((prediction_array.shape[0]))\n",
    "submission.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_extractor_3channel(data_json):\n",
    "    \n",
    "    samples = np.zeros((len(data_json), 224, 224, 3))\n",
    "    angles = np.zeros(len(data_json))\n",
    "\n",
    "    for index, sample in enumerate(data_json):\n",
    "        band_1 = np.asarray(sample['band_1']).reshape(75,75)\n",
    "        band_1 = imresize(band_1, (224,224))\n",
    "        band_2 = np.asarray(sample['band_2']).reshape(75,75)\n",
    "        band_2 = imresize(band_2, (224,224))\n",
    "        band_3 = (band_1 + band_2) / 2\n",
    "        samples[index][:,:,0] = band_1\n",
    "        samples[index][:,:,1] = band_2\n",
    "        samples[index][:,:,2] = band_3\n",
    "        inc_angle = sample['inc_angle']\n",
    "        if isinstance(sample['inc_angle'], str):\n",
    "            angles[index] = angle_avg\n",
    "        else: \n",
    "            angles[index] = sample['inc_angle']\n",
    "            \n",
    "    return samples, angles\n",
    "    \n",
    "train_samples, train_angles = sample_extractor_3channel(train_json)\n",
    "test_samples, test_angles = sample_extractor_3channel(test_json)\n",
    "\n",
    "def mean_zero(samples, angles, band_1_avg, band_2_avg, angle_avg):\n",
    "    for index, sample in enumerate(samples):\n",
    "        samples[index][:,:,0] = np.subtract(sample[:,:,0], band_1_avg)\n",
    "        samples[index][:,:,1] = np.subtract(sample[:,:,1], band_2_avg)\n",
    "        angles[index] = np.subtract(angles[index], angle_avg)\n",
    "        \n",
    "    \n",
    "    # Scale the samples between 0-1\n",
    "    samples[:,:,:,0] = samples[:,:,:,0] + abs(np.amin(samples[:,:,:,0]))\n",
    "    samples[:,:,:,1] = samples[:,:,:,1] + abs(np.amin(samples[:,:,:,1]))\n",
    "    samples[:,:,:,2] = samples[:,:,:,2] + abs(np.amin(samples[:,:,:,2]))\n",
    "        \n",
    "    samples[:,:,:,0] = samples[:,:,:,0] / (np.amax(samples[:,:,:,0]))\n",
    "    samples[:,:,:,1] = samples[:,:,:,1] / (np.amax(samples[:,:,:,1]))\n",
    "    samples[:,:,:,2] = samples[:,:,:,2] / (np.amax(samples[:,:,:,2]))\n",
    "    \n",
    "    print(np.amax(samples[:,:,:,0]))\n",
    "    print(np.amax(samples[:,:,:,1]))\n",
    "    print(np.amax(samples[:,:,:,2]))\n",
    "        \n",
    "    print(np.amin(samples[:,:,:,0]))\n",
    "    print(np.amin(samples[:,:,:,1]))\n",
    "    print(np.amin(samples[:,:,:,2]))\n",
    "        \n",
    "    return samples, angles\n",
    "\n",
    "train_samples, train_angles = mean_zero(train_samples, train_angles, band_1_avg, band_2_avg, angle_avg)\n",
    "test_samples, test_angles = mean_zero(test_samples, test_angles, band_1_avg, band_2_avg, angle_avg)\n",
    "\n",
    "vgg19 = Model(inputs=base_model.input, outputs=base_model.get_layer('block2_pool').output)\n",
    "\n",
    "bottleneck_samples = vgg19.predict(train_samples)\n",
    "\n",
    "\n",
    "\n",
    "num_train = int(len(bottleneck_samples) * 0.2)\n",
    "\n",
    "x_train = bottleneck_samples[num_train:]\n",
    "y_train = labels[num_train:]\n",
    "\n",
    "x_test = bottleneck_samples[:num_train]\n",
    "y_test = labels[:num_train]\n",
    "\n",
    "print(bottleneck_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_input = Input(shape=(56, 56, 128))\n",
    "#x = Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(model_input)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = MaxPooling2D(pool_size=4)(model_input)\n",
    "cnn_out = Flatten()(x)\n",
    "\n",
    "x = Dropout(0.2)(cnn_out)\n",
    "x = Dense(500, activation='relu')(cnn_out)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=model_input, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmsprop = RMSprop(lr=1)\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='nov.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, validation_split=0.2, callbacks=[checkpointer, earlystop], initial_epoch=0, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functional model\n",
    "\n",
    "# Inputs\n",
    "band_input = Input(shape=(75, 75, 2), name='band_input')\n",
    "angle_input = Input(shape=(1,), name='angle_input')\n",
    "\n",
    "\n",
    "# CNN layers\n",
    "#x = Conv2D(filters=64, kernel_size=9, strides=(2, 2), padding='same', activation='relu')(band_input)# Large feature map to start\n",
    "x = Conv2D(filters=16, kernel_size=3, padding='same', activation='relu')(band_input)\n",
    "x = Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = AveragePooling2D(pool_size=2)(x)\n",
    "cnn_out = Flatten()(x)\n",
    "\n",
    "x = Dropout(0.2)(cnn_out)\n",
    "x = Dense(500, activation='relu')(cnn_out)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = concatenate([x, angle_input])\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[band_input, angle_input], outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "prediction_array = model.predict([test_samples, test_angles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vgg 19 inspired\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# avg pooling\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# added deep layer\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new functions\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dropout 0.2\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# earlystop\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Increase dropout to 0.4 for dense layers\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# angle last year, less deep layers\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#moved angle one layer before the end\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#No batch norm\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# More deep layers at end\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Angle added after first dense layer\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dropout in cnn layers\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Angle added to cnn out\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# angle as last layer\n",
    "model.evaluate([x_test, x_2_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VGG 19 inspired\n",
    "\n",
    "# Inputs\n",
    "band_input = Input(shape=(75, 75, 2), name='band_input')\n",
    "angle_input = Input(shape=(1,), name='angle_input')\n",
    "\n",
    "\n",
    "# CNN layers\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')(band_input)\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')(band_input)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Conv2D(filters=512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "cnn_out = Flatten()(x)\n",
    "\n",
    "x = Dense(2048, activation='relu')(cnn_out)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = concatenate([x, angle_input])\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=[band_input, angle_input], outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functional model\n",
    "\n",
    "# Inputs\n",
    "band_input = Input(shape=(75, 75, 2), name='band_input')\n",
    "angle_input = Input(shape=(1,), name='angle_input')\n",
    "\n",
    "\n",
    "# CNN layers\n",
    "x = Conv2D(filters=16, kernel_size=3, padding='same', activation='relu')(band_input)\n",
    "x = Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = AveragePooling2D(pool_size=2)(x)\n",
    "cnn_out = Flatten()(x)\n",
    "\n",
    "x = Dropout(0.2)(cnn_out)\n",
    "x = Dense(500, activation='relu')(cnn_out)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = concatenate([x, angle_input])\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[band_input, angle_input], outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=3, padding='same', activation='relu', \n",
    "                        input_shape=(75, 75, 2))) \n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average = 0\n",
    "for index, sample in enumerate(samples):\n",
    "    average = average + np.average(samples[index][0])\n",
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data is not normalised\n",
    "sum(train_json[0]['band_1']) / len(train_json[0]['band_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.asarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "75*75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = np.asarray([1,2,3,4]).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.add(array, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whole_batch = int(len(train_json) / batch_size)\n",
    "over_batch = int(len(train_json) % batch_size)\n",
    "print(\"{} data points, {} batches of size {}, {} data points left over\".format(len(train_json), whole_batch, batch_size, over_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_json[0]['band_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
